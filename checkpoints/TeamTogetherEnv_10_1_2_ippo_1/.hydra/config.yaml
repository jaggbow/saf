policy:
  _target_: src.policies.ippo.IPPO
  params:
    n_layers: 2
    hidden_dim: 128
    learning_rate: 0.0007
    gamma: 0.99
    gae_lambda: 0.95
    gae: true
    n_agents: ${n_agents}
    ent_coef: 0.01
    vf_coef: 0.5
    norm_adv: true
    clip_coef: 0.2
    clip_vloss: true
    max_grad_norm: 10
    target_kl: null
    update_epochs: 10
    num_minibatches: 1
    rollout_threads: ${rollout_threads}
    env_steps: ${env_steps}
    activation: tanh
    continuous_action: ${continuous_action}
    shared_actor: false
    shared_critic: false
    type: conv
    conv_out_size: 64
env:
  name: TeamTogetherEnv
  family: marlgrid
  rollout_threads: ${rollout_threads}
  continuous_action: ${continuous_action}
  obs_type: image
  params:
    'N': ${n_agents}
    max_cycles: ${env_steps}
    continuous_actions: ${env.continuous_action}
    num_goals: 100
    grid_size: 30
    max_steps: 50
    view_size: 7
    view_tile_size: 4
    clutter_density: 0.1
    coordination: 1
    heterogeneity: 2
buffer:
  n_agents: ${n_agents}
  rollout_threads: ${rollout_threads}
  env_steps: ${env_steps}
  continuous_action: ${continuous_action}
runner:
  _target_: src.runner.PGRunner
  params:
    total_timesteps: 10000000
    rollout_threads: ${rollout_threads}
    env_steps: ${env_steps}
    lr_decay: false
    n_agents: ${n_agents}
    eval_episodes: 32
    checkpoint_dir: null
    experiment_name: ${experiment_name}
    save_dir: outputs/${experiment_name}/
    latent_kl: ${latent_kl}
    comet:
      project_name: team_heterogeneity_baselines
      experiment_name: ${experiment_name}
seed: 1
torch_deterministic: true
cuda: true
rollout_threads: 128
n_agents: 10
continuous_action: false
env_steps: 50
test_mode: false
latent_kl: false
use_policy_pool: false
experiment_name: TeamTogetherEnv_10_1_2_ippo_1
